<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Noella Wang - Stratocumulus</title>
    <link rel="stylesheet" href="/css/style.css">
</head>
<body>

<header>
    <h1>Noella Wang - Stratocumulus</h1>
</header>
<main>
    <section id="project" class="page active">
    <article class="project-entry">
        <div class="project-left">
            <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/A_yPbrjJW1U?si=LPC05nMIS4ojGsIJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
        <div class="project-right">
            <div class="project-header">
                <h4>Project Details:</h4>
                <p><strong>Date:</strong> November 2025</p>
                <p><strong>Role:</strong> Independent Developer (Max, gen~, JavaScript, C++, JUCE)</p>
                <p><strong>Repo:</strong> <a href="https://github.com/nonocutt/Stratocumulus" target="_blank">View on GitHub</a></p>
                <p><strong>Design Document:</strong> <a href="/misc/Stratocumulus.pdf" target="_blank">Download PDF</a></p>
            </div>
            <div class="project-description">
                <p>
                    <em>Stratocumulus</em> is a real-time audio plugin that transforms monophonic audio into a polyphonic granular instrument. Prototyped in <strong>Max/MSP</strong>, it is deployed both as a Max for Live device with a custom JavaScript UI and as a C++ <strong>JUCE</strong> plugin.
                </p>
                <p>
                    The system combines a <strong>YIN</strong>-inspired fundamental frequency tracker with a MIDI-driven granular synthesis engine, enabling harmonically consistent, performance-ready control of live vocal or instrumental signals.
                </p>
                <p>
                    I designed and implemented the full system architecture, DSP, and user interface from scratch, and documented the project in a <strong>LaTeX</strong> design paper modeled after an academic article.
                </p>
                <p>
                    This project comes from my interest in treating sound as both an instrument and a way of “listening” to performers in real time. It reflects the kind of work I hope to pursue at the Media Lab: building responsive instruments and environments that bridge live performance, signal processing, and interactive systems.
                </p>
            </div>
        </div>
    </article>
    </section>
</main>


</body>
</html>